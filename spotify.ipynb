{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all your dependencies as needed\n",
    "# Dependencies and Setup\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import scipy.stats as st\n",
    "from scipy.stats import linregress\n",
    "from pprint import pprint\n",
    "from matplotlib import figure\n",
    "import glob\n",
    "#import squarify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and read all the necessary files for this project\n",
    "# This is mainly dedicated to Rob and Ryan but if you have extra documents to import please do.\n",
    "# Import files\n",
    "csv_list_2019 = glob.glob('**/resources/2019/*.csv', recursive=True)\n",
    "csv_list_2020 = glob.glob('**/resources/2020/*.csv', recursive=True)\n",
    "csv_list_2021 = glob.glob('**/resources/2021/*.csv', recursive=True)\n",
    "csv_list_sweden = glob.glob('**/resources/country_comparison/sweden/*.csv', recursive=True)\n",
    "csv_list_italy = glob.glob('**/resources/country_comparison/italy/*.csv', recursive=True)\n",
    "\n",
    "# Export files\n",
    "final_data_file_2019 = 'output_data/spotify_2019.csv'\n",
    "final_data_file_2020 = 'output_data/Spotify_2020.csv'\n",
    "final_data_file_2021 = 'output_data/Spotify_2021.csv'\n",
    "final_data_file_sweden = 'output_data/sweden_2020.csv'\n",
    "final_data_file_italy = 'output_data/italy_2020.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge csv by Year\n",
    "def merge_csv(csv_list, y):\n",
    "    \n",
    "    # def merge_csv (csv_list):\n",
    "    # print(csv_list)\n",
    "\n",
    "    # list variable\n",
    "    dataframes = []\n",
    "\n",
    "    # set the csv files\n",
    "    for name in csv_list:\n",
    "            dataframes.append(pd.read_csv(name, header=1, encoding = 'UTF-8'))\n",
    "\n",
    "    # set dataframe variables\n",
    "    apr1 = dataframes[0]\n",
    "    apr2 = dataframes[1]\n",
    "    apr3 = dataframes[2]\n",
    "    apr4 = dataframes[3]\n",
    "    aug1 = dataframes[4]\n",
    "    aug2 = dataframes[5]\n",
    "    aug3 = dataframes[6]\n",
    "    aug4 = dataframes[7]\n",
    "    dec1 = dataframes[8]\n",
    "    dec2 = dataframes[9]\n",
    "    dec3 = dataframes[10]\n",
    "    dec4 = dataframes[11]\n",
    "    feb1 = dataframes[12]\n",
    "    feb2 = dataframes[13]\n",
    "    feb3 = dataframes[14]\n",
    "    feb4 = dataframes[15]\n",
    "    jan1 = dataframes[16]\n",
    "    jan2 = dataframes[17]\n",
    "    jan3 = dataframes[18]\n",
    "    jan4 = dataframes[19]\n",
    "    jan5 = dataframes[20]\n",
    "    jul1 = dataframes[21]\n",
    "    jul2 = dataframes[22]\n",
    "    jul3 = dataframes[23]\n",
    "    jul4 = dataframes[24]\n",
    "    jul5 = dataframes[25]\n",
    "    jun1 = dataframes[26]\n",
    "    jun2 = dataframes[27]\n",
    "    jun3 = dataframes[28]\n",
    "    jun4 = dataframes[29]\n",
    "    mar1 = dataframes[30]\n",
    "    mar2 = dataframes[31]\n",
    "    mar3 = dataframes[32]\n",
    "    mar4 = dataframes[33]\n",
    "    may1 = dataframes[34]\n",
    "    may2 = dataframes[35]\n",
    "    may3 = dataframes[36]\n",
    "    may4 = dataframes[37]\n",
    "    may5 = dataframes[38]\n",
    "    nov1 = dataframes[39]\n",
    "    nov2 = dataframes[40]\n",
    "    nov3 = dataframes[41]\n",
    "    nov4 = dataframes[42]\n",
    "    oct1 = dataframes[43]\n",
    "    oct2 = dataframes[44]\n",
    "    oct3 = dataframes[45]\n",
    "    oct4 = dataframes[46]\n",
    "    oct5 = dataframes[47]\n",
    "    sep1 = dataframes[48]\n",
    "    sep2 = dataframes[49]\n",
    "    sep3 = dataframes[50]\n",
    "    sep4 = dataframes[51]\n",
    "\n",
    "    ########### create 'Week' column in dataframes #############\n",
    "    # april\n",
    "    apr1['Week'] = '1'\n",
    "    apr2['Week'] = '2'\n",
    "    apr3['Week'] = '3'\n",
    "    apr4['Week'] = '4'\n",
    "\n",
    "    # august\n",
    "    aug1['Week'] = '1'\n",
    "    aug2['Week'] = '2'\n",
    "    aug3['Week'] = '3'\n",
    "    aug4['Week'] = '4'\n",
    "\n",
    "    # december\n",
    "    dec1['Week'] = '1'\n",
    "    dec2['Week'] = '2'\n",
    "    dec3['Week'] = '3'\n",
    "    dec4['Week'] = '4'\n",
    "\n",
    "    # february\n",
    "    feb1['Week'] = '1'\n",
    "    feb2['Week'] = '2'\n",
    "    feb3['Week'] = '3'\n",
    "    feb4['Week'] = '4'\n",
    "\n",
    "    # january - 5 weeks\n",
    "    jan1['Week'] = '1'\n",
    "    jan2['Week'] = '2'\n",
    "    jan3['Week'] = '3'\n",
    "    jan4['Week'] = '4'\n",
    "    jan5['Week'] = '5'\n",
    "\n",
    "    # july - 5 weeks\n",
    "    jul1['Week'] = '1'\n",
    "    jul2['Week'] = '2'\n",
    "    jul3['Week'] = '3'\n",
    "    jul4['Week'] = '4'\n",
    "    jul5['Week'] = '5'\n",
    "\n",
    "    # june\n",
    "    jun1['Week'] = '1'\n",
    "    jun2['Week'] = '2'\n",
    "    jun3['Week'] = '3'\n",
    "    jun4['Week'] = '4'\n",
    "\n",
    "    # march\n",
    "    mar1['Week'] = '1'\n",
    "    mar2['Week'] = '2'\n",
    "    mar3['Week'] = '3'\n",
    "    mar4['Week'] = '4'\n",
    "\n",
    "    # may - 5 weeks\n",
    "    may1['Week'] = '1'\n",
    "    may2['Week'] = '2'\n",
    "    may3['Week'] = '3'\n",
    "    may4['Week'] = '4'\n",
    "    may5['Week'] = '5'\n",
    "\n",
    "    # november\n",
    "    nov1['Week'] = '1'\n",
    "    nov2['Week'] = '2'\n",
    "    nov3['Week'] = '3'\n",
    "    nov4['Week'] = '4'\n",
    "\n",
    "    # october - 5 weeks\n",
    "    oct1['Week'] = '1'\n",
    "    oct2['Week'] = '2'\n",
    "    oct3['Week'] = '3'\n",
    "    oct4['Week'] = '4'\n",
    "    oct5['Week'] = '5'\n",
    "\n",
    "    # september\n",
    "    sep1['Week'] = '1'\n",
    "    sep2['Week'] = '2'\n",
    "    sep3['Week'] = '3'\n",
    "    sep4['Week'] = '4'\n",
    "\n",
    "    ############# set monthly data frames ##############\n",
    "    # january - 5 weeks\n",
    "    january = [jan1,jan2,jan3,jan4,jan5]\n",
    "    january_df = pd.concat(january)\n",
    "    january_df['Month'] = 'January'\n",
    "    # january_df.to_csv(january_data)\n",
    "\n",
    "    # february\n",
    "    february = [feb1,feb2,feb3,feb4]\n",
    "    february_df = pd.concat(february)\n",
    "    february_df['Month'] = 'February'\n",
    "    # february_df.to_csv(february_data)\n",
    "\n",
    "\n",
    "    # march\n",
    "    march = [mar1,mar2,mar3,mar4]\n",
    "    march_df = pd.concat(march)\n",
    "    march_df['Month'] = 'March'\n",
    "    # march_df.to_csv(march_data)\n",
    "\n",
    "    # april\n",
    "    april = [apr1,apr2,apr3,apr4]\n",
    "    april_df = pd.concat(april)\n",
    "    april_df['Month'] = 'April'\n",
    "    # april_df.to_csv(april_data)\n",
    "\n",
    "    # may - 5 weeks\n",
    "    may = [may1,may2,may3,may4,may5]\n",
    "    may_df = pd.concat(may)\n",
    "    may_df['Month'] = 'May'\n",
    "    # may_df.to_csv(may_data)\n",
    "\n",
    "    # june\n",
    "    june = [jun1,jun2,jun3,jun4]\n",
    "    june_df = pd.concat(june)\n",
    "    june_df['Month'] = 'June'\n",
    "    # june_df.to_csv(june_data)\n",
    "\n",
    "    # july - 5 weeks\n",
    "    july = [jul1,jul2,jul3,jul4,jul5]\n",
    "    july_df = pd.concat(july)\n",
    "    july_df['Month'] = 'July'\n",
    "    # july_df.to_csv(july_data)\n",
    "\n",
    "    # august\n",
    "    august = [aug1,aug2,aug3,aug4]\n",
    "    august_df = pd.concat(august)\n",
    "    august_df['Month'] = 'August'\n",
    "    # august_df.to_csv(august_data)\n",
    "\n",
    "    # september\n",
    "    september = [sep1,sep2,sep3,sep4]\n",
    "    september_df = pd.concat(september)\n",
    "    september_df['Month'] = 'September'\n",
    "    # september_df.to_csv(september_data)\n",
    "\n",
    "    # october - 5 weeks\n",
    "    october = [oct1,oct2,oct3,oct4,oct5]\n",
    "    october_df = pd.concat(october)\n",
    "    october_df['Month'] = 'October'\n",
    "    # october_df.to_csv(october_data)\n",
    "\n",
    "\n",
    "    # november\n",
    "    november = [nov1,nov2,nov3,nov4]\n",
    "    november_df = pd.concat(november)\n",
    "    november_df['Month'] = 'November'\n",
    "    # november_df.to_csv(november_data)\n",
    "\n",
    "    # december\n",
    "    december = [dec1,dec2,dec3,dec4]\n",
    "    december_df = pd.concat(december)\n",
    "    december_df['Month'] = 'December'\n",
    "    # december_df.to_csv(december_data)\n",
    "\n",
    "    # december_df\n",
    "\n",
    "\n",
    "    ########### set up yearly dataframe ##########\n",
    "    months = [january_df, february_df, march_df, april_df, may_df, june_df, july_df, august_df, september_df,\n",
    "             october_df, november_df, december_df]\n",
    "\n",
    "    year = pd.concat(months)\n",
    "\n",
    "    spotify_df = year.loc[:,['Position','Track Name', 'Artist', 'Streams', 'Week', 'Month']]\n",
    "    #     spotify2019_df\n",
    "    spotify_df['Year'] = y\n",
    "#     spotify_df['Year'] = '2019'\n",
    "\n",
    "\n",
    "    return spotify_df\n",
    "\n",
    "\n",
    "# Function to merge csv is 2021\n",
    "def merge_csv21(csv_list, y):\n",
    "    dataframes = []\n",
    "\n",
    "\n",
    "    # df_names\n",
    "    for name in csv_list:\n",
    "            dataframes.append(pd.read_csv(name, header=1, encoding = 'UTF-8'))\n",
    "    # set dataframe variables\n",
    "\n",
    "    feb1 = dataframes[0]\n",
    "    feb2 = dataframes[1]\n",
    "    jan1 = dataframes[2]\n",
    "    jan2 = dataframes[3]\n",
    "    jan3 = dataframes[4]\n",
    "    jan4 = dataframes[5]\n",
    "\n",
    "    # create 'Week' column in dataframes\n",
    "    # february\n",
    "    feb1['Week'] = '1'\n",
    "    feb2['Week'] = '2'\n",
    "\n",
    "    # january - 5 weeks\n",
    "    jan1['Week'] = '1'\n",
    "    jan2['Week'] = '2'\n",
    "    jan3['Week'] = '3'\n",
    "    jan4['Week'] = '4'\n",
    "\n",
    "    # set monthly data frames\n",
    "    # january\n",
    "    january = [jan1,jan2,jan3,jan4]\n",
    "    january_df = pd.concat(january)\n",
    "    january_df['Month'] = 'January'\n",
    "    \n",
    "    # february\n",
    "    february = [feb1,feb2]\n",
    "    february_df = pd.concat(february)\n",
    "    february_df['Month'] = 'February'\n",
    "\n",
    "    # set up yearly dataframe\n",
    "    months = [january_df, february_df]\n",
    "    year = pd.concat(months)\n",
    "    spotify_df = year.loc[:,['Position','Track Name', 'Artist', 'Streams', 'Week', 'Month']]\n",
    "    spotify_df['Year'] = y\n",
    "    return spotify_df\n",
    "\n",
    "\n",
    "# Function to merge csv by Country\n",
    "def merge_csv_country(csv_list, y):    \n",
    "    dataframes = []\n",
    "\n",
    "    # df_names\n",
    "    for name in csv_list:\n",
    "            dataframes.append(pd.read_csv(name, header=1, encoding = 'UTF-8'))\n",
    "    # set dataframe variables\n",
    "    apr1 = dataframes[0]\n",
    "    apr2 = dataframes[1]\n",
    "    apr3 = dataframes[2]\n",
    "    apr4 = dataframes[3]\n",
    "    apr5 = dataframes[4]\n",
    "    feb1 = dataframes[5]\n",
    "    feb2 = dataframes[6]\n",
    "    feb3 = dataframes[7]\n",
    "    feb4 = dataframes[8]\n",
    "    jan1 = dataframes[9]\n",
    "    jan2 = dataframes[10]\n",
    "    jan3 = dataframes[11]\n",
    "    jan4 = dataframes[12]\n",
    "    jan5 = dataframes[13]\n",
    "    jun1 = dataframes[14]\n",
    "    jun2 = dataframes[15]\n",
    "    jun3 = dataframes[16]\n",
    "    jun4 = dataframes[17]\n",
    "    mar1 = dataframes[18]\n",
    "    mar2 = dataframes[19]\n",
    "    mar3 = dataframes[20]\n",
    "    mar4 = dataframes[21]\n",
    "    may1 = dataframes[22]\n",
    "    may2 = dataframes[23]\n",
    "    may3 = dataframes[24]\n",
    "    may4 = dataframes[25]\n",
    "\n",
    "    # create 'Week' column in dataframes\n",
    "    # april\n",
    "    apr1['Week'] = '1'\n",
    "    apr2['Week'] = '2'\n",
    "    apr3['Week'] = '3'\n",
    "    apr4['Week'] = '4'\n",
    "    apr5['Week'] = '5'\n",
    "    # february\n",
    "    feb1['Week'] = '1'\n",
    "    feb2['Week'] = '2'\n",
    "    feb3['Week'] = '3'\n",
    "    feb4['Week'] = '4'\n",
    "    # january - 5 weeks\n",
    "    jan1['Week'] = '1'\n",
    "    jan2['Week'] = '2'\n",
    "    jan3['Week'] = '3'\n",
    "    jan4['Week'] = '4'\n",
    "    jan5['Week'] = '5'\n",
    "    # june\n",
    "    jun1['Week'] = '1'\n",
    "    jun2['Week'] = '2'\n",
    "    jun3['Week'] = '3'\n",
    "    jun4['Week'] = '4'\n",
    "    # march\n",
    "    mar1['Week'] = '1'\n",
    "    mar2['Week'] = '2'\n",
    "    mar3['Week'] = '3'\n",
    "    mar4['Week'] = '4'\n",
    "    # may - 5 weeks\n",
    "    may1['Week'] = '1'\n",
    "    may2['Week'] = '2'\n",
    "    may3['Week'] = '3'\n",
    "    may4['Week'] = '4'\n",
    "\n",
    "    # set monthly data frames\n",
    "    # january\n",
    "    january = [jan1,jan2,jan3,jan4,jan5]\n",
    "    january_df = pd.concat(january)\n",
    "    january_df['Month'] = 'January'\n",
    "\n",
    "    # february\n",
    "    february = [feb1,feb2,feb3,feb4]\n",
    "    february_df = pd.concat(february)\n",
    "    february_df['Month'] = 'February'\n",
    "\n",
    "    # march\n",
    "    march = [mar1,mar2,mar3,mar4]\n",
    "    march_df = pd.concat(march)\n",
    "    march_df['Month'] = 'March'\n",
    "\n",
    "    # april\n",
    "    april = [apr1,apr2,apr3,apr4,apr5]\n",
    "    april_df = pd.concat(april)\n",
    "    april_df['Month'] = 'April'\n",
    "\n",
    "    # may\n",
    "    may = [may1,may2,may3,may4]\n",
    "    may_df = pd.concat(may)\n",
    "    may_df['Month'] = 'May'\n",
    "\n",
    "    # june\n",
    "    june = [jun1,jun2,jun3,jun4]\n",
    "    june_df = pd.concat(june)\n",
    "    june_df['Month'] = 'June'\n",
    "\n",
    "    # set up yearly dataframe\n",
    "    months = [january_df, february_df, march_df, april_df, may_df, june_df]\n",
    "    year = pd.concat(months)\n",
    "    spotify_df = year.loc[:,['Position','Track Name', 'Artist', 'Streams', 'Week', 'Month']]\n",
    "    spotify_df['Year'] = y\n",
    "    \n",
    "    return spotify_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and create Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Rob and Ryans section. If you need to create new cells, just make sure it is above previous section to avoid confusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 2019 csv files and export it\n",
    "spotify2019_df = merge_csv(csv_list_2019, '2019')\n",
    "spotify2019_df.to_csv(final_data_file_2019, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 2020 csv files and export it\n",
    "spotify2020_df = merge_csv(csv_list_2020, '2020')\n",
    "spotify2020_df.to_csv(final_data_file_2020, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 2021 csv files and export it\n",
    "spotify2021_df = merge_csv21(csv_list_2021, '2021')\n",
    "spotify2021_df.to_csv(final_data_file_2021, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Sweden 2020 csv files and export it\n",
    "spotify2020_sweden_df = merge_csv_country(csv_list_sweden, '2020')\n",
    "spotify2020_sweden_df.to_csv(final_data_file_sweden, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Italy 2020 csv files and export it\n",
    "spotify2020_italy_df = merge_csv_country(csv_list_italy, '2020')\n",
    "spotify2020_italy_df.to_csv(final_data_file_italy, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique data - artists/track/genre 2019\n",
    "unique_artists19 = spotify2019_df['Artist'].unique()\n",
    "print(f'Total unique artists: {len(unique_artists19)}')\n",
    "\n",
    "unique_tracks19 = spotify2019_df['Track Name'].unique()\n",
    "print(f'Total unique tracks: {len(unique_tracks19)}')\n",
    "\n",
    "total_streams19 = (spotify2019_df['Streams']/1000000000).sum()\n",
    "print(f'Total streams for 2019 top 200: {total_streams19} billion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique data - artists/track/genre 2020\n",
    "unique_artists20 = spotify2020_df['Artist'].unique()\n",
    "print(f'Total unique artists: {len(unique_artists20)}')\n",
    "\n",
    "unique_tracks20 = spotify2020_df['Track Name'].unique()\n",
    "print(f'Total unique tracks: {len(unique_tracks20)}')\n",
    "\n",
    "total_streams20 = (spotify2020_df['Streams']/1000000000).sum()\n",
    "print(f'Total streams for 2019 top 200: {total_streams20} billion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Calls section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Kelvyn's section to make API Calls from Spotify.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Francisco section for his Plots\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Ryan's section for his Plots\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is John's section for his Plots\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Kelvyn's Section for his Plots\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Ryan's section for his Plots\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
