{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "%matplotlib inline\n",
    "from spotify_client import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "from matplotlib import rcParams \n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib\n",
    "import plotly_express as ex\n",
    "import joypy\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import time\n",
    "import scipy.stats as st\n",
    "import math\n",
    "from math import pi\n",
    "import scipy.stats as st\n",
    "from scipy.stats import linregress\n",
    "from pprint import pprint\n",
    "import string\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import io\n",
    "import squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = 'Please enter Spotify Client ID'\n",
    "client_secret = 'Please enter Spotify Client Secret'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import files\n",
    "csv_list_2019 = glob.glob('**/resources/2019/*.csv', recursive=True)\n",
    "csv_list_2020 = glob.glob('**/resources/2020/*.csv', recursive=True)\n",
    "csv_list_2021 = glob.glob('**/resources/2021/*.csv', recursive=True)\n",
    "csv_list_sweden = glob.glob('**/resources/country_comparison/sweden/*.csv', recursive=True)\n",
    "csv_list_italy = glob.glob('**/resources/country_comparison/italy/*.csv', recursive=True)\n",
    "\n",
    "# Export files\n",
    "final_data_file_2019 = 'output_data/spotify_2019.csv'\n",
    "final_data_file_2020 = 'output_data/Spotify_2020.csv'\n",
    "final_data_file_2021 = 'output_data/Spotify_2021.csv'\n",
    "final_data_file_sweden = 'output_data/sweden_2020.csv'\n",
    "final_data_file_italy = 'output_data/italy_2020.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------#\n",
    "#                    Function to merge csv                      #\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "# Function to merge csv by Year\n",
    "def merge_csv19(csv_list, y):\n",
    "\n",
    "    # list variable\n",
    "    dataframes = []\n",
    "\n",
    "    # set the csv files\n",
    "    for name in csv_list:\n",
    "        dataframes.append(pd.read_csv(name, header=1, encoding = 'UTF-8'))\n",
    "\n",
    "    # set dataframe variables\n",
    "    apr1 = dataframes[0]\n",
    "    apr2 = dataframes[1]\n",
    "    apr3 = dataframes[2]\n",
    "    apr4 = dataframes[3]\n",
    "    aug1 = dataframes[4]\n",
    "    aug2 = dataframes[5]\n",
    "    aug3 = dataframes[6]\n",
    "    aug4 = dataframes[7]\n",
    "    dec1 = dataframes[8]\n",
    "    dec2 = dataframes[9]\n",
    "    dec3 = dataframes[10]\n",
    "    dec4 = dataframes[11]\n",
    "    feb1 = dataframes[12]\n",
    "    feb2 = dataframes[13]\n",
    "    feb3 = dataframes[14]\n",
    "    feb4 = dataframes[15]\n",
    "    jan1 = dataframes[16]\n",
    "    jan2 = dataframes[17]\n",
    "    jan3 = dataframes[18]\n",
    "    jan4 = dataframes[19]\n",
    "    jan5 = dataframes[20]\n",
    "    jul1 = dataframes[21]\n",
    "    jul2 = dataframes[22]\n",
    "    jul3 = dataframes[23]\n",
    "    jul4 = dataframes[24]\n",
    "    jul5 = dataframes[25]\n",
    "    jun1 = dataframes[26]\n",
    "    jun2 = dataframes[27]\n",
    "    jun3 = dataframes[28]\n",
    "    jun4 = dataframes[29]\n",
    "    mar1 = dataframes[30]\n",
    "    mar2 = dataframes[31]\n",
    "    mar3 = dataframes[32]\n",
    "    mar4 = dataframes[33]\n",
    "    may1 = dataframes[34]\n",
    "    may2 = dataframes[35]\n",
    "    may3 = dataframes[36]\n",
    "    may4 = dataframes[37]\n",
    "    may5 = dataframes[38]\n",
    "    nov1 = dataframes[39]\n",
    "    nov2 = dataframes[40]\n",
    "    nov3 = dataframes[41]\n",
    "    nov4 = dataframes[42]\n",
    "    oct1 = dataframes[43]\n",
    "    oct2 = dataframes[44]\n",
    "    oct3 = dataframes[45]\n",
    "    oct4 = dataframes[46]\n",
    "    oct5 = dataframes[47]\n",
    "    sep1 = dataframes[48]\n",
    "    sep2 = dataframes[49]\n",
    "    sep3 = dataframes[50]\n",
    "    sep4 = dataframes[51]\n",
    "\n",
    "    ########### create 'Week' column in dataframes #############\n",
    "    # april\n",
    "    apr1['Week'] = '1'\n",
    "    apr2['Week'] = '2'\n",
    "    apr3['Week'] = '3'\n",
    "    apr4['Week'] = '4'\n",
    "\n",
    "    # august\n",
    "    aug1['Week'] = '1'\n",
    "    aug2['Week'] = '2'\n",
    "    aug3['Week'] = '3'\n",
    "    aug4['Week'] = '4'\n",
    "\n",
    "    # december\n",
    "    dec1['Week'] = '1'\n",
    "    dec2['Week'] = '2'\n",
    "    dec3['Week'] = '3'\n",
    "    dec4['Week'] = '4'\n",
    "\n",
    "    # february\n",
    "    feb1['Week'] = '1'\n",
    "    feb2['Week'] = '2'\n",
    "    feb3['Week'] = '3'\n",
    "    feb4['Week'] = '4'\n",
    "\n",
    "    # january - 5 weeks\n",
    "    jan1['Week'] = '1'\n",
    "    jan2['Week'] = '2'\n",
    "    jan3['Week'] = '3'\n",
    "    jan4['Week'] = '4'\n",
    "    jan5['Week'] = '5'\n",
    "\n",
    "    # july - 5 weeks\n",
    "    jul1['Week'] = '1'\n",
    "    jul2['Week'] = '2'\n",
    "    jul3['Week'] = '3'\n",
    "    jul4['Week'] = '4'\n",
    "    jul5['Week'] = '5'\n",
    "\n",
    "    # june\n",
    "    jun1['Week'] = '1'\n",
    "    jun2['Week'] = '2'\n",
    "    jun3['Week'] = '3'\n",
    "    jun4['Week'] = '4'\n",
    "\n",
    "    # march\n",
    "    mar1['Week'] = '1'\n",
    "    mar2['Week'] = '2'\n",
    "    mar3['Week'] = '3'\n",
    "    mar4['Week'] = '4'\n",
    "\n",
    "    # may - 5 weeks\n",
    "    may1['Week'] = '1'\n",
    "    may2['Week'] = '2'\n",
    "    may3['Week'] = '3'\n",
    "    may4['Week'] = '4'\n",
    "    may5['Week'] = '5'\n",
    "\n",
    "    # november\n",
    "    nov1['Week'] = '1'\n",
    "    nov2['Week'] = '2'\n",
    "    nov3['Week'] = '3'\n",
    "    nov4['Week'] = '4'\n",
    "\n",
    "    # october - 5 weeks\n",
    "    oct1['Week'] = '1'\n",
    "    oct2['Week'] = '2'\n",
    "    oct3['Week'] = '3'\n",
    "    oct4['Week'] = '4'\n",
    "    oct5['Week'] = '5'\n",
    "\n",
    "    # september\n",
    "    sep1['Week'] = '1'\n",
    "    sep2['Week'] = '2'\n",
    "    sep3['Week'] = '3'\n",
    "    sep4['Week'] = '4'\n",
    "\n",
    "    ############# set monthly data frames ##############\n",
    "    # january - 5 weeks\n",
    "    january = [jan1,jan2,jan3,jan4,jan5]\n",
    "    january_df = pd.concat(january)\n",
    "    january_df['Month'] = 'January'\n",
    "\n",
    "    # february\n",
    "    february = [feb1,feb2,feb3,feb4]\n",
    "    february_df = pd.concat(february)\n",
    "    february_df['Month'] = 'February'\n",
    "\n",
    "    # march\n",
    "    march = [mar1,mar2,mar3,mar4]\n",
    "    march_df = pd.concat(march)\n",
    "    march_df['Month'] = 'March'\n",
    "\n",
    "    # april\n",
    "    april = [apr1,apr2,apr3,apr4]\n",
    "    april_df = pd.concat(april)\n",
    "    april_df['Month'] = 'April'\n",
    "\n",
    "    # may - 5 weeks\n",
    "    may = [may1,may2,may3,may4,may5]\n",
    "    may_df = pd.concat(may)\n",
    "    may_df['Month'] = 'May'\n",
    "\n",
    "    # june\n",
    "    june = [jun1,jun2,jun3,jun4]\n",
    "    june_df = pd.concat(june)\n",
    "    june_df['Month'] = 'June'\n",
    "\n",
    "    # july - 5 weeks\n",
    "    july = [jul1,jul2,jul3,jul4,jul5]\n",
    "    july_df = pd.concat(july)\n",
    "    july_df['Month'] = 'July'\n",
    "\n",
    "    # august\n",
    "    august = [aug1,aug2,aug3,aug4]\n",
    "    august_df = pd.concat(august)\n",
    "    august_df['Month'] = 'August'\n",
    "\n",
    "    # september\n",
    "    september = [sep1,sep2,sep3,sep4]\n",
    "    september_df = pd.concat(september)\n",
    "    september_df['Month'] = 'September'\n",
    "\n",
    "    # october - 5 weeks\n",
    "    october = [oct1,oct2,oct3,oct4,oct5]\n",
    "    october_df = pd.concat(october)\n",
    "    october_df['Month'] = 'October'\n",
    "\n",
    "    # november\n",
    "    november = [nov1,nov2,nov3,nov4]\n",
    "    november_df = pd.concat(november)\n",
    "    november_df['Month'] = 'November'\n",
    "\n",
    "    # december\n",
    "    december = [dec1,dec2,dec3,dec4]\n",
    "    december_df = pd.concat(december)\n",
    "    december_df['Month'] = 'December'\n",
    "\n",
    "\n",
    "    ########### set up yearly dataframe ##########\n",
    "    months = [january_df, february_df, march_df, april_df, may_df, june_df, july_df, august_df, september_df,\n",
    "             october_df, november_df, december_df]\n",
    "\n",
    "    year = pd.concat(months)\n",
    "\n",
    "    spotify_df = year.loc[:,['Position','Track Name', 'Artist', 'Streams', 'Week', 'Month']]\n",
    "    spotify_df['Year'] = y\n",
    "\n",
    "\n",
    "    return spotify_df\n",
    "\n",
    "\n",
    "# Function to merge csv in 2020\n",
    "\n",
    "    \n",
    "\n",
    "# Function to merge csv in 2021\n",
    "def merge_csv21(csv_list, y):\n",
    "    dataframes = []\n",
    "\n",
    "\n",
    "    # df_names\n",
    "    for name in csv_list:\n",
    "            dataframes.append(pd.read_csv(name, header=1, encoding = 'UTF-8'))\n",
    "    # set dataframe variables\n",
    "\n",
    "    feb1 = dataframes[0]\n",
    "    feb2 = dataframes[1]\n",
    "    jan1 = dataframes[2]\n",
    "    jan2 = dataframes[3]\n",
    "    jan3 = dataframes[4]\n",
    "    jan4 = dataframes[5]\n",
    "\n",
    "    # create 'Week' column in dataframes\n",
    "    # february\n",
    "    feb1['Week'] = '1'\n",
    "    feb2['Week'] = '2'\n",
    "\n",
    "    # january - 5 weeks\n",
    "    jan1['Week'] = '1'\n",
    "    jan2['Week'] = '2'\n",
    "    jan3['Week'] = '3'\n",
    "    jan4['Week'] = '4'\n",
    "\n",
    "    # set monthly data frames\n",
    "    # january\n",
    "    january = [jan1,jan2,jan3,jan4]\n",
    "    january_df = pd.concat(january)\n",
    "    january_df['Month'] = 'January'\n",
    "    \n",
    "    # february\n",
    "    february = [feb1,feb2]\n",
    "    february_df = pd.concat(february)\n",
    "    february_df['Month'] = 'February'\n",
    "\n",
    "    # set up yearly dataframe\n",
    "    months = [january_df, february_df]\n",
    "    year = pd.concat(months)\n",
    "    spotify_df = year.loc[:,['Position','Track Name', 'Artist', 'Streams', 'Week', 'Month']]\n",
    "    spotify_df['Year'] = y\n",
    "    return spotify_df\n",
    "\n",
    "\n",
    "# Function to merge csv by Country\n",
    "def merge_csv_country(csv_list, y):    \n",
    "    dataframes = []\n",
    "\n",
    "    # df_names\n",
    "    for name in csv_list:\n",
    "        dataframes.append(pd.read_csv(name, header=1, encoding = 'UTF-8'))\n",
    "    # set dataframe variables\n",
    "    apr1 = dataframes[0]\n",
    "    apr2 = dataframes[1]\n",
    "    apr3 = dataframes[2]\n",
    "    apr4 = dataframes[3]\n",
    "    apr5 = dataframes[4]\n",
    "    feb1 = dataframes[5]\n",
    "    feb2 = dataframes[6]\n",
    "    feb3 = dataframes[7]\n",
    "    feb4 = dataframes[8]\n",
    "    jan1 = dataframes[9]\n",
    "    jan2 = dataframes[10]\n",
    "    jan3 = dataframes[11]\n",
    "    jan4 = dataframes[12]\n",
    "    jan5 = dataframes[13]\n",
    "    jun1 = dataframes[14]\n",
    "    jun2 = dataframes[15]\n",
    "    jun3 = dataframes[16]\n",
    "    jun4 = dataframes[17]\n",
    "    mar1 = dataframes[18]\n",
    "    mar2 = dataframes[19]\n",
    "    mar3 = dataframes[20]\n",
    "    mar4 = dataframes[21]\n",
    "    may1 = dataframes[22]\n",
    "    may2 = dataframes[23]\n",
    "    may3 = dataframes[24]\n",
    "    may4 = dataframes[25]\n",
    "\n",
    "    # create 'Week' column in dataframes\n",
    "    # april\n",
    "    apr1['Week'] = '1'\n",
    "    apr2['Week'] = '2'\n",
    "    apr3['Week'] = '3'\n",
    "    apr4['Week'] = '4'\n",
    "    apr5['Week'] = '5'\n",
    "    # february\n",
    "    feb1['Week'] = '1'\n",
    "    feb2['Week'] = '2'\n",
    "    feb3['Week'] = '3'\n",
    "    feb4['Week'] = '4'\n",
    "    # january - 5 weeks\n",
    "    jan1['Week'] = '1'\n",
    "    jan2['Week'] = '2'\n",
    "    jan3['Week'] = '3'\n",
    "    jan4['Week'] = '4'\n",
    "    jan5['Week'] = '5'\n",
    "    # june\n",
    "    jun1['Week'] = '1'\n",
    "    jun2['Week'] = '2'\n",
    "    jun3['Week'] = '3'\n",
    "    jun4['Week'] = '4'\n",
    "    # march\n",
    "    mar1['Week'] = '1'\n",
    "    mar2['Week'] = '2'\n",
    "    mar3['Week'] = '3'\n",
    "    mar4['Week'] = '4'\n",
    "    # may - 5 weeks\n",
    "    may1['Week'] = '1'\n",
    "    may2['Week'] = '2'\n",
    "    may3['Week'] = '3'\n",
    "    may4['Week'] = '4'\n",
    "\n",
    "    # set monthly data frames\n",
    "    # january\n",
    "    january = [jan1,jan2,jan3,jan4,jan5]\n",
    "    january_df = pd.concat(january)\n",
    "    january_df['Month'] = 'January'\n",
    "\n",
    "    # february\n",
    "    february = [feb1,feb2,feb3,feb4]\n",
    "    february_df = pd.concat(february)\n",
    "    february_df['Month'] = 'February'\n",
    "\n",
    "    # march\n",
    "    march = [mar1,mar2,mar3,mar4]\n",
    "    march_df = pd.concat(march)\n",
    "    march_df['Month'] = 'March'\n",
    "\n",
    "    # april\n",
    "    april = [apr1,apr2,apr3,apr4,apr5]\n",
    "    april_df = pd.concat(april)\n",
    "    april_df['Month'] = 'April'\n",
    "\n",
    "    # may\n",
    "    may = [may1,may2,may3,may4]\n",
    "    may_df = pd.concat(may)\n",
    "    may_df['Month'] = 'May'\n",
    "\n",
    "    # june\n",
    "    june = [jun1,jun2,jun3,jun4]\n",
    "    june_df = pd.concat(june)\n",
    "    june_df['Month'] = 'June'\n",
    "\n",
    "    # set up yearly dataframe\n",
    "    months = [january_df, february_df, march_df, april_df, may_df, june_df]\n",
    "    year = pd.concat(months)\n",
    "    spotify_df = year.loc[:,['Position','Track Name', 'Artist', 'Streams', 'Week', 'Month']]\n",
    "    spotify_df['Year'] = y\n",
    "\n",
    "    return spotify_df\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------#\n",
    "#                 Spotify API related functions                 #\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "# Make Spotify API calls and extract data\n",
    "def call_api (df):\n",
    "    df['*Artist Name'] = \"\"\n",
    "    df['Artist ID'] = \"\"\n",
    "    df['Artist Followers'] = \"\"\n",
    "    df['Artist Genre'] = \"\"\n",
    "    df['Artist Popularity'] = \"\"\n",
    "    df['*Track Name'] = \"\"\n",
    "    df['Track ID'] = \"\"\n",
    "    df['Track Duration (ms)'] = \"\"\n",
    "    df['Track Popularity'] = \"\"\n",
    "    df['Album Name'] = \"\"\n",
    "    df['Album ID'] = \"\"\n",
    "    df['Album Released Date'] = \"\"\n",
    "    df['Album Total Tracks'] = \"\"\n",
    "    df['Acousticness'] = \"\"\n",
    "    df['Danceability'] = \"\"\n",
    "    df['Energy'] = \"\"\n",
    "    df['Instrumentalness'] = \"\"\n",
    "    df['Key'] = \"\"\n",
    "    df['Liveness'] = \"\"\n",
    "    df['Loudness'] = \"\"\n",
    "    df['Mode'] = \"\"\n",
    "    df['Speechiness'] = \"\"\n",
    "    df['Tempo'] = \"\"\n",
    "    df['Time Signature'] = \"\"\n",
    "    df['Valence'] = \"\"\n",
    "    NA = 'N/A'\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        search_results = spotify.search({'track':row['Track Name'], \n",
    "                                         'artist':row['Artist']\n",
    "                                         },\n",
    "                                        search_type='track')\n",
    "        try:\n",
    "            # Append values into a list\n",
    "            # Artist info\n",
    "            artist_name = search_results['tracks']['items'][0]['artists'][0]['name']\n",
    "            artist_id = search_results['tracks']['items'][0]['artists'][0]['id']\n",
    "\n",
    "            # Track info\n",
    "            track_name = search_results['tracks']['items'][0]['name']\n",
    "            track_id = search_results['tracks']['items'][0]['id']\n",
    "            track_duration_ms = search_results['tracks']['items'][0]['duration_ms']\n",
    "            track_popularity = search_results['tracks']['items'][0]['popularity']\n",
    "\n",
    "            # Album info\n",
    "            album_name = search_results['tracks']['items'][0]['album']['name']\n",
    "            album_id = search_results['tracks']['items'][0]['album']['id']\n",
    "            album_released_date = search_results['tracks']['items'][0]['album']['release_date']\n",
    "            album_total_tracks = search_results['tracks']['items'][0]['album']['total_tracks']\n",
    "\n",
    "            # Extra artist info when searched with artist_id\n",
    "            artist_results = spotify.get_artist(artist_id)\n",
    "            artist_followers = artist_results['followers']['total']\n",
    "            artist_genre = artist_results['genres'][0] #Output usually 3, just picking first one\n",
    "            artist_popularity = artist_results['popularity']\n",
    "            \n",
    "            # Audio features\n",
    "            audio_features = spotify.get_audio_features(track_id)\n",
    "            acousticness = audio_features['acousticness']\n",
    "            danceability = audio_features['danceability']\n",
    "            energy = audio_features['energy']\n",
    "            instrumentalness = audio_features['instrumentalness']\n",
    "            key = audio_features['key']\n",
    "            liveness = audio_features['liveness']\n",
    "            loudness = audio_features['loudness']\n",
    "            mode = audio_features['mode']\n",
    "            speechiness = audio_features['speechiness']\n",
    "            tempo = audio_features['tempo']\n",
    "            time_signature = audio_features['time_signature']\n",
    "            valence = audio_features['valence']\n",
    "\n",
    "            df.loc[index, '*Artist Name'] = artist_name\n",
    "            df.loc[index, 'Artist ID'] = artist_id\n",
    "            df.loc[index, 'Artist Followers'] = artist_followers\n",
    "            df.loc[index, 'Artist Genre'] = artist_genre\n",
    "            df.loc[index, 'Artist Popularity'] = artist_popularity \n",
    "            df.loc[index, '*Track Name'] = track_name\n",
    "            df.loc[index, 'Track ID'] = track_id\n",
    "            df.loc[index, 'Track Duration (ms)'] = track_duration_ms\n",
    "            df.loc[index, 'Track Popularity'] = track_popularity\n",
    "            df.loc[index, 'Album Name'] = album_name\n",
    "            df.loc[index, 'Album ID'] = album_id\n",
    "            df.loc[index, 'Album Released Date'] = album_released_date\n",
    "            df.loc[index, 'Album Total Tracks'] = album_total_tracks\n",
    "            df.loc[index, 'Acousticness'] = acousticness\n",
    "            df.loc[index, 'Danceability'] = danceability\n",
    "            df.loc[index, 'Energy'] = energy\n",
    "            df.loc[index, 'Instrumentalness'] = instrumentalness\n",
    "            df.loc[index, 'Key'] = key\n",
    "            df.loc[index, 'Liveness'] = liveness\n",
    "            df.loc[index, 'Loudness'] = loudness\n",
    "            df.loc[index, 'Mode'] = mode\n",
    "            df.loc[index, 'Speechiness'] = speechiness\n",
    "            df.loc[index, 'Tempo'] = tempo\n",
    "            df.loc[index, 'Time Signature'] = time_signature\n",
    "            df.loc[index, 'Valence'] = valence\n",
    "\n",
    "        except:\n",
    "            df.loc[index, '*Artist Name'] = NA\n",
    "            df.loc[index, 'Artist ID'] = NA\n",
    "            df.loc[index, 'Artist Followers'] = NA\n",
    "            df.loc[index, 'Artist Genre'] = NA\n",
    "            df.loc[index, 'Artist Popularity'] = NA \n",
    "            df.loc[index, '*Track Name'] = NA\n",
    "            df.loc[index, 'Track ID'] = NA\n",
    "            df.loc[index, 'Track Duration (ms)'] = NA\n",
    "            df.loc[index, 'Track Popularity'] = NA\n",
    "            df.loc[index, 'Album Name'] = NA\n",
    "            df.loc[index, 'Album ID'] = NA\n",
    "            df.loc[index, 'Album Released Date'] = NA\n",
    "            df.loc[index, 'Album Total Tracks'] = NA\n",
    "            df.loc[index, 'Acousticness'] = NA\n",
    "            df.loc[index, 'Danceability'] = NA\n",
    "            df.loc[index, 'Energy'] = NA\n",
    "            df.loc[index, 'Instrumentalness'] = NA\n",
    "            df.loc[index, 'Key'] = NA\n",
    "            df.loc[index, 'Liveness'] = NA\n",
    "            df.loc[index, 'Loudness'] = NA\n",
    "            df.loc[index, 'Mode'] = NA\n",
    "            df.loc[index, 'Speechiness'] = NA\n",
    "            df.loc[index, 'Tempo'] = NA\n",
    "            df.loc[index, 'Time Signature'] = NA\n",
    "            df.loc[index, 'Valence'] = NA\n",
    "            pass\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to go through N/A values and attempt to get results\n",
    "def call_api_na (df):\n",
    "    NA = 'N/A'\n",
    "    counter=0   \n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        if row['*Artist Name'] == 'N/A':\n",
    "            search_results = spotify.search({'track':row['Track Name'], \n",
    "                                             'artist':row['Artist'],\n",
    "                                             },\n",
    "                                             search_type='track')\n",
    "            \n",
    "            # If nothing is found check different track name\n",
    "            if search_results['tracks']['total'] == 0:\n",
    "                search_results = spotify.search({'track':row['Track Name'][:8],\n",
    "                                                 'artist':row['Artist']\n",
    "                                                 },\n",
    "                                                 search_type='track')\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                # Append values into a list\n",
    "                # Artist info\n",
    "                artist_name = search_results['tracks']['items'][0]['artists'][0]['name']\n",
    "                artist_id = search_results['tracks']['items'][0]['artists'][0]['id']\n",
    "\n",
    "                # Track info\n",
    "                track_name = search_results['tracks']['items'][0]['name']\n",
    "                track_id = search_results['tracks']['items'][0]['id']\n",
    "                track_duration_ms = search_results['tracks']['items'][0]['duration_ms']\n",
    "                track_popularity = search_results['tracks']['items'][0]['popularity']\n",
    "\n",
    "                # Album info\n",
    "                album_name = search_results['tracks']['items'][0]['album']['name']\n",
    "                album_id = search_results['tracks']['items'][0]['album']['id']\n",
    "                album_released_date = search_results['tracks']['items'][0]['album']['release_date']\n",
    "                album_total_tracks = search_results['tracks']['items'][0]['album']['total_tracks']\n",
    "\n",
    "                # Extra artist info when searched with artist_id\n",
    "                artist_results = spotify.get_artist(artist_id)\n",
    "                artist_followers = artist_results['followers']['total']\n",
    "                artist_genre = artist_results['genres'][0] #Output usually 3, just picking first one\n",
    "                artist_popularity = artist_results['popularity']\n",
    "\n",
    "                # Audio features\n",
    "                audio_features = spotify.get_audio_features(track_id)\n",
    "                acousticness = audio_features['acousticness']\n",
    "                danceability = audio_features['danceability']\n",
    "                energy = audio_features['energy']\n",
    "                instrumentalness = audio_features['instrumentalness']\n",
    "                key = audio_features['key']\n",
    "                liveness = audio_features['liveness']\n",
    "                loudness = audio_features['loudness']\n",
    "                mode = audio_features['mode']\n",
    "                speechiness = audio_features['speechiness']\n",
    "                tempo = audio_features['tempo']\n",
    "                time_signature = audio_features['time_signature']\n",
    "                valence = audio_features['valence']\n",
    "\n",
    "                df.loc[index, '*Artist Name'] = artist_name\n",
    "                df.loc[index, 'Artist ID'] = artist_id\n",
    "                df.loc[index, 'Artist Followers'] = artist_followers\n",
    "                df.loc[index, 'Artist Genre'] = artist_genre\n",
    "                df.loc[index, 'Artist Popularity'] = artist_popularity \n",
    "                df.loc[index, '*Track Name'] = track_name\n",
    "                df.loc[index, 'Track ID'] = track_id\n",
    "                df.loc[index, 'Track Duration (ms)'] = track_duration_ms\n",
    "                df.loc[index, 'Track Popularity'] = track_popularity\n",
    "                df.loc[index, 'Album Name'] = album_name\n",
    "                df.loc[index, 'Album ID'] = album_id\n",
    "                df.loc[index, 'Album Released Date'] = album_released_date\n",
    "                df.loc[index, 'Album Total Tracks'] = album_total_tracks\n",
    "                df.loc[index, 'Acousticness'] = acousticness\n",
    "                df.loc[index, 'Danceability'] = danceability\n",
    "                df.loc[index, 'Energy'] = energy\n",
    "                df.loc[index, 'Instrumentalness'] = instrumentalness\n",
    "                df.loc[index, 'Key'] = key\n",
    "                df.loc[index, 'Liveness'] = liveness\n",
    "                df.loc[index, 'Loudness'] = loudness\n",
    "                df.loc[index, 'Mode'] = mode\n",
    "                df.loc[index, 'Speechiness'] = speechiness\n",
    "                df.loc[index, 'Tempo'] = tempo\n",
    "                df.loc[index, 'Time Signature'] = time_signature\n",
    "                df.loc[index, 'Valence'] = valence         \n",
    "\n",
    "            except:\n",
    "                df.loc[index, '*Artist Name'] = NA\n",
    "                df.loc[index, 'Artist ID'] = NA\n",
    "                df.loc[index, 'Artist Followers'] = NA\n",
    "                df.loc[index, 'Artist Genre'] = NA\n",
    "                df.loc[index, 'Artist Popularity'] = NA \n",
    "                df.loc[index, '*Track Name'] = NA\n",
    "                df.loc[index, 'Track ID'] = NA\n",
    "                df.loc[index, 'Track Duration (ms)'] = NA\n",
    "                df.loc[index, 'Track Popularity'] = NA\n",
    "                df.loc[index, 'Album Name'] = NA\n",
    "                df.loc[index, 'Album ID'] = NA\n",
    "                df.loc[index, 'Album Released Date'] = NA\n",
    "                df.loc[index, 'Album Total Tracks'] = NA\n",
    "                df.loc[index, 'Acousticness'] = NA\n",
    "                df.loc[index, 'Danceability'] = NA\n",
    "                df.loc[index, 'Energy'] = NA\n",
    "                df.loc[index, 'Instrumentalness'] = NA\n",
    "                df.loc[index, 'Key'] = NA\n",
    "                df.loc[index, 'Liveness'] = NA\n",
    "                df.loc[index, 'Loudness'] = NA\n",
    "                df.loc[index, 'Mode'] = NA\n",
    "                df.loc[index, 'Speechiness'] = NA\n",
    "                df.loc[index, 'Tempo'] = NA\n",
    "                df.loc[index, 'Time Signature'] = NA\n",
    "                df.loc[index, 'Valence'] = NA\n",
    "                pass\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------#\n",
    "#     Data verification and organization related functions      #\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "# Include only important columns to be exported in csv\n",
    "def clean_data(df):       \n",
    "    df = df[['Position', 'Track Name', 'Artist', 'Streams', 'Week', 'Month',\n",
    "             'Year', 'Artist Followers', 'Artist Genre', 'Artist Popularity',\n",
    "             'Track Popularity', 'Track Duration (ms)', 'Album Name', 'Album Total Tracks', \n",
    "             'Album Released Date', 'Acousticness', 'Danceability', 'Energy', 'Instrumentalness', \n",
    "             'Key', 'Liveness', 'Loudness', 'Mode', 'Speechiness', 'Tempo', 'Time Signature', 'Valence']]\n",
    "    return df\n",
    "\n",
    "# Remove character from Track Name and Artist to avoid search issues\n",
    "def remove_characters(df):\n",
    "    df[['Track Name', 'Artist']] = df[['Track Name', 'Artist']].replace({\"'\":\"\"}, regex=True)\n",
    "    return df\n",
    "\n",
    "# Count N/A values in Data Frame\n",
    "def count_na(df):\n",
    "    #Count N/A values in Data Frame\n",
    "    counter = 0\n",
    "    for value in df['*Artist Name']:\n",
    "        if value == 'N/A':\n",
    "            counter +=1\n",
    "    return counter\n",
    "\n",
    "# Check if Artist Names match\n",
    "def name_check(df):    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['Artist'] == row['*Artist Name']:\n",
    "            df['Artist Check'] = 'True'\n",
    "        else:\n",
    "            df['Artist Check'] = 'False'\n",
    "\n",
    "    #Count False Artist values\n",
    "    counter = 0\n",
    "    for value in df['Artist Check']:\n",
    "        if value == 'False':\n",
    "            counter +=1\n",
    "    return counter\n",
    "\n",
    "#Check if Track Names match\n",
    "def track_check(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Track Name'] == row['*Track Name']:\n",
    "            df['Track Check'] = 'True'\n",
    "        else:\n",
    "            df['Track Check'] = 'False'\n",
    "\n",
    "    #Count False Track values\n",
    "    counter = 0\n",
    "    for value in df['Track Check']:\n",
    "        if value == 'False':\n",
    "            counter +=1\n",
    "    return counter\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------#\n",
    "#                Different Plots related functions              #\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "# Function to generate three Radar Charts\n",
    "def radar_plot(group,*args):\n",
    "    count = 1\n",
    "    nplots = len(args)  \n",
    "    \n",
    "    for df in args:\n",
    "        x = 5\n",
    "        color = f\"#{random.randrange(0x1000000):06x}\"\n",
    "        name = ([x for x in globals() if globals()[x] is df][0])\n",
    "        name = string.capwords(name.replace(\"_\", \" \"))\n",
    "        if group == True:\n",
    "            df = df.groupby(['Week', 'Month']).mean()\n",
    "            x = 1\n",
    "                \n",
    "        fig = plt.figure(figsize=(16,16))\n",
    "        ax = plt.subplot((220 + count), polar='True')\n",
    "\n",
    "        categories = df.iloc[0,x:].index.tolist()\n",
    "        N = len(categories)\n",
    "\n",
    "        for xx in range(len(df)):\n",
    "            values = df[['Acousticness', 'Danceability', 'Energy', \n",
    "                                'Valence', 'Speechiness', 'Liveness', 'Instrumentalness']].iloc[xx].values.tolist()\n",
    "            angles = [n / float(N) * 2 * pi for n in  range(N)]\n",
    "\n",
    "            try:\n",
    "                values = values + [df[['Acousticness', 'Danceability', 'Energy', \n",
    "                                'Valence', 'Speechiness', 'Liveness', 'Instrumentalness']].iloc[xx+1].values[0]]\n",
    "                angles += angles[:1]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            # xticks\n",
    "            plt.xticks(angles[:-1], categories)\n",
    "            for label,i in zip(ax.get_xticklabels(),range(0,len(angles))):\n",
    "                angle_rad=angles[i]\n",
    "                if angle_rad <= pi/2:\n",
    "                    ha= 'left'\n",
    "                    va= \"bottom\"\n",
    "\n",
    "                elif pi/2 < angle_rad <= pi:\n",
    "                    ha= 'right'\n",
    "                    va= \"bottom\"\n",
    "\n",
    "                elif pi < angle_rad <= (3*pi/2):\n",
    "                    ha= 'right'\n",
    "                    va= \"top\"  \n",
    "\n",
    "                elif (11*pi/6) > angle_rad > (5*pi/3):\n",
    "                    ha= 'left'\n",
    "                    va= \"bottom\" \n",
    "\n",
    "                else:\n",
    "                    ha= 'right'\n",
    "                    va= \"bottom\"\n",
    "\n",
    "                label.set_verticalalignment(va)\n",
    "                label.set_horizontalalignment(ha)    \n",
    "                \n",
    "\n",
    "            plt.polar(angles, values, alpha=0.5, lw=1, color=color)\n",
    "\n",
    "            # xticks\n",
    "            plt.xticks(angles[:-1], categories)\n",
    "\n",
    "\n",
    "        # yticks\n",
    "        ax.set_rlabel_position(0)\n",
    "        plt.yticks([0.25,0.50,0.75], color='grey', size=10)\n",
    "        plt.ylim(0,1)\n",
    "\n",
    "        plt.fill(angles, values, alpha=0.3, color = color)\n",
    "\n",
    "        title = f\"Audio features for {name}\"\n",
    "        plt.title(title)\n",
    "        count += 1 \n",
    "        plt.savefig('Radar_plot'+str(count)+'.png')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Function to generate Density Plot \n",
    "def density_plot(df, df2, df3, month1, month2, month3, label1, label2, label3, audiofeat, title):\n",
    "    count += 1 \n",
    "    # Draw Plot\n",
    "    plt.figure(figsize=(16,10), dpi= 80)\n",
    "    sns.kdeplot(df.loc[df['Month'] == month1, audiofeat], shade=True, color=\"g\", label=label1, alpha=.7)\n",
    "    sns.kdeplot(df2.loc[df2['Month'] == month2, audiofeat], shade=True, color=\"deeppink\", label=label2, alpha=.7)\n",
    "    sns.kdeplot(df3.loc[df3['Month'] == month3, audiofeat], shade=True, color=\"dodgerblue\", label=label3, alpha=.7)\n",
    "\n",
    "    # Decoration\n",
    "    plt.title(title, fontsize=22)\n",
    "    plt.legend()\n",
    "    plt.savefig('Density_plot'+str(count)+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv20(csv_list, y):\n",
    "    dataframes = []\n",
    "    # df_names\n",
    "    for name in csv_list:\n",
    "            dataframes.append(pd.read_csv(name, header=1, encoding = 'UTF-8'))\n",
    "    # set dataframe variables\n",
    "    apr1 = dataframes[0]\n",
    "    apr2 = dataframes[1]\n",
    "    apr3 = dataframes[2]\n",
    "    apr4 = dataframes[3]\n",
    "    apr5 = dataframes[4]\n",
    "    aug1 = dataframes[5]\n",
    "    aug2 = dataframes[6]\n",
    "    aug3 = dataframes[7]\n",
    "    aug4 = dataframes[8]\n",
    "    dec1 = dataframes[9]\n",
    "    dec2 = dataframes[10]\n",
    "    dec3 = dataframes[11]\n",
    "    dec4 = dataframes[12]\n",
    "    feb1 = dataframes[13]\n",
    "    feb2 = dataframes[14]\n",
    "    feb3 = dataframes[15]\n",
    "    feb4 = dataframes[16]\n",
    "    jan1 = dataframes[17]\n",
    "    jan2 = dataframes[18]\n",
    "    jan3 = dataframes[19]\n",
    "    jan4 = dataframes[20]\n",
    "    jan5 = dataframes[21]\n",
    "    jul1 = dataframes[22]\n",
    "    jul2 = dataframes[23]\n",
    "    jul3 = dataframes[24]\n",
    "    jul4 = dataframes[25]\n",
    "    jul5 = dataframes[26]\n",
    "    jun1 = dataframes[27]\n",
    "    jun2 = dataframes[28]\n",
    "    jun3 = dataframes[29]\n",
    "    jun4 = dataframes[30]\n",
    "    mar1 = dataframes[31]\n",
    "    mar2 = dataframes[32]\n",
    "    mar3 = dataframes[33]\n",
    "    mar4 = dataframes[34]\n",
    "    may1 = dataframes[35]\n",
    "    may2 = dataframes[36]\n",
    "    may3 = dataframes[37]\n",
    "    may4 = dataframes[38]\n",
    "    nov1 = dataframes[39]\n",
    "    nov2 = dataframes[40]\n",
    "    nov3 = dataframes[41]\n",
    "    nov4 = dataframes[42]\n",
    "    oct1 = dataframes[43]\n",
    "    oct2 = dataframes[44]\n",
    "    oct3 = dataframes[45]\n",
    "    oct4 = dataframes[46]\n",
    "    oct5 = dataframes[47]\n",
    "    sep1 = dataframes[48]\n",
    "    sep2 = dataframes[49]\n",
    "    sep3 = dataframes[50]\n",
    "    sep4 = dataframes[51]\n",
    "\n",
    "    # create 'Week' column in dataframes\n",
    "    # april\n",
    "    apr1['Week'] = '1'\n",
    "    apr2['Week'] = '2'\n",
    "    apr3['Week'] = '3'\n",
    "    apr4['Week'] = '4'\n",
    "    apr5['Week'] = '5'\n",
    "    # august\n",
    "    aug1['Week'] = '1'\n",
    "    aug2['Week'] = '2'\n",
    "    aug3['Week'] = '3'\n",
    "    aug4['Week'] = '4'\n",
    "    # december\n",
    "    dec1['Week'] = '1'\n",
    "    dec2['Week'] = '2'\n",
    "    dec3['Week'] = '3'\n",
    "    dec4['Week'] = '4'\n",
    "    # february\n",
    "    feb1['Week'] = '1'\n",
    "    feb2['Week'] = '2'\n",
    "    feb3['Week'] = '3'\n",
    "    feb4['Week'] = '4'\n",
    "    # january - 5 weeks\n",
    "    jan1['Week'] = '1'\n",
    "    jan2['Week'] = '2'\n",
    "    jan3['Week'] = '3'\n",
    "    jan4['Week'] = '4'\n",
    "    jan5['Week'] = '5'\n",
    "    # july - 5 weeks\n",
    "    jul1['Week'] = '1'\n",
    "    jul2['Week'] = '2'\n",
    "    jul3['Week'] = '3'\n",
    "    jul4['Week'] = '4'\n",
    "    jul5['Week'] = '5'\n",
    "    # june\n",
    "    jun1['Week'] = '1'\n",
    "    jun2['Week'] = '2'\n",
    "    jun3['Week'] = '3'\n",
    "    jun4['Week'] = '4'\n",
    "    # march\n",
    "    mar1['Week'] = '1'\n",
    "    mar2['Week'] = '2'\n",
    "    mar3['Week'] = '3'\n",
    "    mar4['Week'] = '4'\n",
    "    # may - 5 weeks\n",
    "    may1['Week'] = '1'\n",
    "    may2['Week'] = '2'\n",
    "    may3['Week'] = '3'\n",
    "    may4['Week'] = '4'\n",
    "    # november\n",
    "    nov1['Week'] = '1'\n",
    "    nov2['Week'] = '2'\n",
    "    nov3['Week'] = '3'\n",
    "    nov4['Week'] = '4'\n",
    "    # october\n",
    "    oct1['Week'] = '1'\n",
    "    oct2['Week'] = '2'\n",
    "    oct3['Week'] = '3'\n",
    "    oct4['Week'] = '4'\n",
    "    oct5['Week'] = '5'\n",
    "    # september\n",
    "    sep1['Week'] = '1'\n",
    "    sep2['Week'] = '2'\n",
    "    sep3['Week'] = '3'\n",
    "    sep4['Week'] = '4'\n",
    "    sep4\n",
    "    \n",
    "    # set monthly data frames\n",
    "    # january\n",
    "    january = [jan1,jan2,jan3,jan4,jan5]\n",
    "    january_df = pd.concat(january)\n",
    "    january_df['Month'] = 'January'\n",
    "    \n",
    "    # february\n",
    "    february = [feb1,feb2,feb3,feb4]\n",
    "    february_df = pd.concat(february)\n",
    "    february_df['Month'] = 'February'\n",
    "    \n",
    "    # march\n",
    "    march = [mar1,mar2,mar3,mar4]\n",
    "    march_df = pd.concat(march)\n",
    "    march_df['Month'] = 'March'\n",
    "\n",
    "    # april\n",
    "    april = [apr1,apr2,apr3,apr4,apr5]\n",
    "    april_df = pd.concat(april)\n",
    "    april_df['Month'] = 'April'\n",
    "\n",
    "    # may\n",
    "    may = [may1,may2,may3,may4]\n",
    "    may_df = pd.concat(may)\n",
    "    may_df['Month'] = 'May'\n",
    "\n",
    "    # june\n",
    "    june = [jun1,jun2,jun3,jun4]\n",
    "    june_df = pd.concat(june)\n",
    "    june_df['Month'] = 'June'\n",
    "\n",
    "    # july\n",
    "    july = [jul1,jul2,jul3,jul4,jul5]\n",
    "    july_df = pd.concat(july)\n",
    "    july_df['Month'] = 'July'\n",
    "\n",
    "    # august\n",
    "    august = [aug1,aug2,aug3,aug4]\n",
    "    august_df = pd.concat(august)\n",
    "    august_df['Month'] = 'August'\n",
    "\n",
    "    # september\n",
    "    september = [sep1,sep2,sep3,sep4]\n",
    "    september_df = pd.concat(september)\n",
    "    september_df['Month'] = 'September'\n",
    "\n",
    "    # october\n",
    "    october = [oct1,oct2,oct3,oct4,oct5]\n",
    "    october_df = pd.concat(october)\n",
    "    october_df['Month'] = 'October'\n",
    "\n",
    "    # november\n",
    "    november = [nov1,nov2,nov3,nov4]\n",
    "    november_df = pd.concat(november)\n",
    "    november_df['Month'] = 'November'\n",
    "\n",
    "    # december\n",
    "    december = [dec1,dec2,dec3,dec4]\n",
    "    december_df = pd.concat(december)\n",
    "    december_df['Month'] = 'December'\n",
    "    \n",
    "    # set up yearly dataframe\n",
    "    months = [january_df, february_df, march_df, april_df, may_df, june_df, july_df, august_df, september_df,\n",
    "             october_df, november_df, december_df]\n",
    "    year = pd.concat(months)\n",
    "    year\n",
    "    spotify_df = year.loc[:,['Position','Track Name', 'Artist', 'Streams', 'Week', 'Month']]\n",
    "    spotify_df['Year'] = '2020'\n",
    "    \n",
    "    return spotify_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and create Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 2019 csv files and export it\n",
    "spotify2019_df = merge_csv19(csv_list_2019, '2019')\n",
    "spotify2019_df.to_csv(final_data_file_2019, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 2020 csv files and export it\n",
    "spotify2020_df = merge_csv20(csv_list_2020, '2020')\n",
    "spotify2020_df.to_csv(final_data_file_2020, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 2021 csv files and export it\n",
    "spotify2021_df = merge_csv21(csv_list_2021, '2021')\n",
    "spotify2021_df.to_csv(final_data_file_2021, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Sweden 2020 csv files and export it\n",
    "spotify2020_sweden_df = merge_csv_country(csv_list_sweden, '2020')\n",
    "spotify2020_sweden_df.to_csv(final_data_file_sweden, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Italy 2020 csv files and export it\n",
    "spotify2020_italy_df = merge_csv_country(csv_list_italy, '2020')\n",
    "spotify2020_italy_df.to_csv(final_data_file_italy, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique data - artists/track/genre 2019\n",
    "unique_artists19 = spotify2019_df['Artist'].unique()\n",
    "print(f'Total unique artists: {len(unique_artists19)}')\n",
    "\n",
    "unique_tracks19 = spotify2019_df['Track Name'].unique()\n",
    "print(f'Total unique tracks: {len(unique_tracks19)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique data - artists/track/genre 2020\n",
    "unique_artists20 = spotify2020_df['Artist'].unique()\n",
    "print(f'Total unique artists: {len(unique_artists20)}')\n",
    "\n",
    "unique_tracks20 = spotify2020_df['Track Name'].unique()\n",
    "print(f'Total unique tracks: {len(unique_tracks20)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Calls section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Spotify API token to make calls\n",
    "spotify = SpotifyAPI(client_id, client_secret)\n",
    "\n",
    "# Make a copy of main Data Frames\n",
    "spotify19_df = spotify2019_df.copy()\n",
    "spotify20_df = spotify2020_df.copy()\n",
    "spotify21_df = spotify2021_df.copy()\n",
    "spotify_sweden_df = spotify2020_italy_df.copy()\n",
    "spotify_italy_df = spotify2020_italy_df.copy()\n",
    "\n",
    "# Remove unwanted character from all dataframes\n",
    "spotify19_df = remove_characters(spotify19_df)\n",
    "spotify20_df = remove_characters(spotify20_df)\n",
    "spotify21_df = remove_characters(spotify21_df)\n",
    "spotify_sweden_df = remove_characters(spotify_sweden_df)\n",
    "spotify_italy_df = remove_characters(spotify_italy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify 2019 Data / API Call\n",
    "spotify19_df = call_api(spotify19_df)\n",
    "\n",
    "# Spotify 2020 Data / API Call\n",
    "spotify20_df = call_api(spotify20_df)\n",
    "\n",
    "# Spotify 2021 Data / API Call\n",
    "spotify21_df = call_api(spotify21_df)\n",
    "\n",
    "# Spotify Sweden 2020 Data / API Call\n",
    "spotify_sweden_df = call_api(spotify_sweden_df)\n",
    "\n",
    "# Spotify Italy 2020 Data / API Call\n",
    "spotify_italy_df = call_api(spotify_italy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count N/A values Before in each Data Frame\n",
    "na_19 = count_na(spotify19_df)\n",
    "na_20 = count_na(spotify20_df)\n",
    "na_21 = count_na(spotify21_df)\n",
    "na_sweden = count_na(spotify_sweden_df)\n",
    "na_italy = count_na(spotify_italy_df)\n",
    "\n",
    "print(f\"Spotify 2019 has {na_19} N/A value / Spotify 2020 has {na_20} N/A value / Spotify 2021 has {na_21} N/A value\")\n",
    "print(f\"Spotify Sweden 2020 has {na_sweden} N/A value / Spotify Italy 2020 has {na_italy} N/A value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through N/A values in second API call\n",
    "for number in range(50):\n",
    "    spotify19_df = call_api_na(spotify19_df)\n",
    "    spotify20_df = call_api_na(spotify20_df)\n",
    "    spotify21_df = call_api_na(spotify21_df)\n",
    "    spotify_sweden_df = call_api_na(spotify_sweden_df)\n",
    "    spotify_italy_df = call_api_na(spotify_italy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count N/A values After in each Data Frame\n",
    "na_19 = count_na(spotify19_df)\n",
    "na_20 = count_na(spotify20_df)\n",
    "na_21 = count_na(spotify21_df)\n",
    "na_sweden = count_na(spotify_sweden_df)\n",
    "na_italy = count_na(spotify_italy_df)\n",
    "\n",
    "print(f\"Spotify 2019 has {na_19} N/A value / Spotify 2020 has {na_20} N/A value / Spotify 2021 has {na_21} N/A value\")\n",
    "print(f\"Spotify Sweden 2020 has {na_sweden} N/A value / Spotify Italy 2020 has {na_italy} N/A value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace N/A to NaN\n",
    "spotify19_df_na = spotify19_df.replace('N/A', np.nan)\n",
    "spotify20_df_na = spotify20_df.replace('N/A', np.nan)\n",
    "spotify21_df_na = spotify21_df.replace('N/A', np.nan)\n",
    "spotify_sweden_df_na = spotify_sweden_df.replace('N/A', np.nan)\n",
    "spotify_italy_df_na = spotify_italy_df.replace('N/A', np.nan)\n",
    "\n",
    "# Drop NaN rows\n",
    "spotify19_df_na = spotify19_df_na.dropna().reset_index(drop=True)\n",
    "spotify20_df_na = spotify20_df_na.dropna().reset_index(drop=True)\n",
    "spotify21_df_na = spotify21_df_na.dropna().reset_index(drop=True)\n",
    "spotify_sweden_df_na = spotify_sweden_df_na.dropna().reset_index(drop=True)\n",
    "spotify_italy_df_na = spotify_italy_df_na.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Artist Names match\n",
    "name_19 = name_check(spotify19_df_na)\n",
    "name_20 = name_check(spotify20_df_na)\n",
    "name_21 = name_check(spotify21_df_na)\n",
    "name_sweden = name_check(spotify_sweden_df_na)\n",
    "name_italy = name_check(spotify_italy_df_na)\n",
    "\n",
    "#Check if Track Names match\n",
    "track_19 = track_check(spotify19_df_na)\n",
    "track_20 = track_check(spotify20_df_na)\n",
    "track_21 = track_check(spotify21_df_na)\n",
    "track_sweden = track_check(spotify_sweden_df_na)\n",
    "track_italy = track_check(spotify_italy_df_na)\n",
    "\n",
    "print(f\"Artists in 2019 returned {name_19} unmatched rows / Artists in 2020 returned {name_20} unmatched rows / Artists in 2021 returned {name_21} unmatched rows\")\n",
    "print(f\"Tracks in 2019 returned {track_19} unmatched rows / Tracks in 2020 returned {track_20} unmatched rows / Tracks in 2021 returned {track_21} unmatched rows\")\n",
    "print(f\"Artists in Sweden 2020 returned {name_sweden} unmatched rows / Artists in Italy 2020 returned {name_italy} unmatched rows\")\n",
    "print(f\"Tracks in Sweden 2020 returned {track_sweden} unmatched rows / Tracks in Italy 2020 returned {track_italy} unmatched rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed unnecessary columns from Data Frames\n",
    "# Spotify 2019 Data / Including only needed columns\n",
    "original_spotify19_df = clean_data(spotify19_df_na)\n",
    "\n",
    "# Spotify 2020 Data / Including only needed columns\n",
    "original_spotify20_df = clean_data(spotify20_df_na)\n",
    "\n",
    "# Spotify 2021 Data / Including only needed columns\n",
    "original_spotify21_df = clean_data(spotify21_df_na)\n",
    "\n",
    "# Spotify Sweden 2019 Data / Including only needed columns\n",
    "original_spotify_sweden_df = clean_data(spotify_sweden_df_na)\n",
    "\n",
    "# Spotify Italy 2020 Data / Including only needed columns\n",
    "original_spotify_italy_df = clean_data(spotify_italy_df_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export files with Spotify API data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv files with Spotify API data\n",
    "# Export 2019 updated csv file\n",
    "original_spotify19_df.to_csv('output_data/Original_Spotify2019_Updated_2-20-21.csv', index=False, header=True)\n",
    "\n",
    "# Export 2020 updated csv file\n",
    "original_spotify20_df.to_csv('output_data/Original_Spotify2020_Updated_2-20-21.csv', index=False, header=True)\n",
    "\n",
    "# Export 2021 updated csv file\n",
    "original_spotify21_df.to_csv('output_data/Original_Spotify2021_Updated_2-20-21.csv', index=False, header=True)\n",
    "\n",
    "# Export Sweden 2020 updated csv file\n",
    "original_spotify_sweden_df.to_csv('output_data/Spotify_Sweden_2020_Updated_2-20-21.csv', index=False, header=True)\n",
    "\n",
    "# Export Italy 2020 updated csv file\n",
    "original_spotify_italy_df.to_csv('output_data/Spotify_Italy_2020_Updated_2-20-21.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Streams Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of Data Frames\n",
    "#2019 CSV\n",
    "sd_2019_df = spotify2019_df.copy()\n",
    "\n",
    "#2020 CSV to DF\n",
    "sd_2020_df = spotify2020_df.copy()\n",
    "\n",
    "#combined csvs\n",
    "sd_combined_df = pd.concat([sd_2019_df, sd_2020_df])\n",
    "\n",
    "#stream by year\n",
    "sum_2020 = sd_2020_df.groupby(\"Year\")[\"Streams\"].sum()\n",
    "sum_2019 = sd_2019_df.groupby(\"Year\")[\"Streams\"].sum()\n",
    "\n",
    "#streams by year\n",
    "sum_by_year_df = sd_combined_df.groupby(\"Year\")[\"Streams\"].sum()\n",
    "\n",
    "stream_delta = (sum_2020 - sum_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------#\n",
    "#        Bar Plot Streams per year      #\n",
    "#---------------------------------------#\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "fig.text(.30,.76, \"30.48 Billion\", ha = \"center\");\n",
    "fig.text(.73,.76, \"28.56 Billion\", ha = \"center\");\n",
    "x1 = [0,1,2,3]\n",
    "label_number = ['10 Billion','30 Billion']\n",
    "ax1.set_yticks(x1)\n",
    "ax1.set_yticklabels(label_number, minor=False, rotation=45)\n",
    "\n",
    "#style\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "#Generate a bar plot showing the total number of measurements taken on each drug regimen using pandas.\n",
    "#x axis\n",
    "x_axis = sd_combined_df[\"Year\"].unique()\n",
    "plt.title(\"Number of Spotify Streams By Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "\n",
    "#y axis\n",
    "y_axis = sum_by_year_df\n",
    "plt.ylabel(\"Total Number of Spotify Streams\")\n",
    "fig, ax = plt.bar(x_axis, y_axis)\n",
    "\n",
    "#ticks and rotation\n",
    "tick_locations = [value for value in x_axis]\n",
    "plt.xticks(tick_locations, x_axis, rotation = \"30\")\n",
    "rcParams[\"figure.figsize\"]= 5, 7\n",
    "plt.ylim(1000000000,30000000000)\n",
    "plt.yticks([1000000000,30000000000])\n",
    "ax.figure.savefig('output_plots/Bar_plot_yearly.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#streams by month 2019 vs 2020\n",
    "new_sd_2019_df = sd_2019_df.groupby(\"Month\")[\"Streams\"].sum()\n",
    "new_sd_2019_df.index = pd.CategoricalIndex(new_sd_2019_df.index, categories=['Previous December','January', 'February', 'March', 'April','May','June', 'July', 'August','September', 'October', 'November', 'December'], ordered=True)\n",
    "new_sd_2019_df = new_sd_2019_df.sort_index()\n",
    "new_sd_2020_df = sd_2020_df.groupby(\"Month\")[\"Streams\"].sum()\n",
    "new_sd_2020_df = new_sd_2020_df\n",
    "\n",
    "#sort months by categorical index\n",
    "new_sd_2020_df.index = pd.CategoricalIndex(new_sd_2020_df.index, categories=['Previous December','January', 'February', 'March', 'April','May','June', 'July', 'August','September', 'October', 'November', 'December'], ordered=True)\n",
    "new_sd_2020_df = new_sd_2020_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------#\n",
    "#    line plot 2019 vs 2020 by month    #\n",
    "#---------------------------------------#\n",
    "fig, ax = plt.subplots()\n",
    "#April Text\n",
    "fig.text(.3,.52, \"Drake - Toosie Slide\", ha = \"center\");\n",
    "fig.text(.3,.55, \"The Scotts Released\", ha = \"center\");\n",
    "\n",
    "#may 2019 text\n",
    "fig.text(.22,.31, \"Restrictions/Lockdowns Begin\", ha = \"center\");\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(new_sd_2019_df, markersize=12, marker=\"o\")\n",
    "plt.plot(new_sd_2020_df, markersize=12, marker=\"o\")\n",
    "plt.legend([2019, 2020])\n",
    "stream_label = np.arange(0, 4, .5)\n",
    "ax.set_yticklabels(stream_label)\n",
    "rcParams[\"figure.figsize\"]= 18, 5\n",
    "\n",
    "#title and axis labels\n",
    "plt.title(\"Spotify Streams by Month 2019 vs. 2020\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of Streams (Billions)\");\n",
    "fig.savefig('output_plots/Line_plot_2019vs2020.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genres Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 genre variable\n",
    "genres19 = original_spotify19_df\n",
    "genres19.drop_duplicates(subset = 'Track Name', keep = False, inplace = True)\n",
    "\n",
    "# 2020 genre variable\n",
    "genres20 = original_spotify20_df\n",
    "genres20.drop_duplicates(subset = 'Track Name', keep = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------#\n",
    "#        2019 genre treemapping         #\n",
    "#---------------------------------------#\n",
    "# prep data\n",
    "df = genres19.groupby('Artist Genre').size().reset_index(name='counts')\n",
    "labels = df.apply(lambda x: str(x[0]) + \"\\n (\" + str(x[1]) + \")\", axis=1)\n",
    "sizes = df['counts'].values.tolist()\n",
    "colors = [plt.cm.Spectral(i/float(len(labels))) for i in range(len(labels))]\n",
    "\n",
    "# draw plot\n",
    "plt.figure(figsize=(15,10), dpi= 300)\n",
    "squarify.plot(sizes=sizes, label=labels, color=colors, alpha=.8)\n",
    "\n",
    "# set plot and save fig\n",
    "plt.title('Spotify 2019 Top 200 Genre Count')\n",
    "plt.axis('off')\n",
    "plt.savefig('output_plots/2019genre.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------#\n",
    "#        2020 genre treemapping         #\n",
    "#---------------------------------------#\n",
    "# prep data\n",
    "df = genres20.groupby('Artist Genre').size().reset_index(name='counts')\n",
    "labels = df.apply(lambda x: str(x[0]) + \"\\n (\" + str(x[1]) + \")\", axis=1)\n",
    "sizes = df['counts'].values.tolist()\n",
    "colors = [plt.cm.Spectral(i/float(len(labels))) for i in range(len(labels))]\n",
    "\n",
    "# draw plot\n",
    "plt.figure(figsize=(15,10), dpi= 300)\n",
    "squarify.plot(sizes=sizes, label=labels, color=colors, alpha=.8)\n",
    "\n",
    "# set plot and save fig\n",
    "plt.title('Spotify 2020 Top 200 Genre Count')\n",
    "plt.axis('off')\n",
    "plt.savefig('output_plots/2020genre.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USA Audio Analysis Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = original_spotify19_df.copy()\n",
    "corr_music_features = cleaned_df[['Danceability', 'Energy', 'Speechiness']].corr()\n",
    "\n",
    "fig,ax= plt.subplots(figsize=(10,7))\n",
    "sns.heatmap(corr_music_features, xticklabels=corr_music_features.columns, yticklabels=corr_music_features.columns, cmap='RdYlGn', center=0, annot=True)\n",
    "plt.title('Correllogram of Music Features 2019', fontsize=22)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='Energy', y='Danceability', data=cleaned_df[['Energy', 'Danceability']], kind=\"hex\").set_axis_labels(\"Energy\", \"Danceability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_2 = original_spotify19_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_music_features_2 = cleaned_df[['Danceability', 'Energy', 'Speechiness']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots(figsize=(10,7))\n",
    "sns.heatmap(corr_music_features_2, xticklabels=corr_music_features_2.columns, yticklabels=corr_music_features.columns, cmap='RdYlGn', center=0, annot=True)\n",
    "plt.title('Correllogram of Music Features 2020', fontsize=22)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='Energy', y='Danceability', data=cleaned_df_2[['Energy', 'Danceability']], kind=\"hex\").set_axis_labels(\"Energy\", \"Danceability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweden, Italy & USA Audio Analysis Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of Data Frames\n",
    "spotify_sweden = original_spotify_sweden_df.copy()\n",
    "spotify_italy = original_spotify_italy_df.copy()\n",
    "spotify_usa  = original_spotify20_df.copy()\n",
    "\n",
    "# Filter Columns\n",
    "spotify_usa_plot = spotify_usa[['Track Name', 'Artist', 'Week', 'Month', 'Year', 'Acousticness', 'Danceability', 'Energy', \n",
    "                             'Valence', 'Speechiness', 'Liveness', 'Instrumentalness']]\n",
    "spotify_sweden_plot = spotify_sweden[['Track Name', 'Artist', 'Week', 'Month', 'Year', 'Acousticness', 'Danceability', 'Energy', \n",
    "                             'Valence', 'Speechiness', 'Liveness', 'Instrumentalness']]\n",
    "spotify_italy_plot = spotify_italy[['Track Name', 'Artist', 'Week', 'Month', 'Year', 'Acousticness', 'Danceability', 'Energy', \n",
    "                             'Valence', 'Speechiness', 'Liveness', 'Instrumentalness']]\n",
    "\n",
    "# USA data filtered\n",
    "spotify_usa_feb = spotify_usa_plot[(spotify_usa_plot['Month'] == 'February')]\n",
    "spotify_usa_mar = spotify_usa_plot[(spotify_usa_plot['Month'] == 'March')]\n",
    "spotify_usa_apr = spotify_usa_plot[(spotify_usa_plot['Month'] == 'April')] #Data missing from dataframe\n",
    "\n",
    "# Sweden data filtered\n",
    "spotify_sweden_feb = spotify_sweden_plot[(spotify_sweden_plot['Month'] == 'February')]\n",
    "spotify_sweden_mar = spotify_sweden_plot[(spotify_sweden_plot['Month'] == 'March')]\n",
    "spotify_sweden_apr = spotify_sweden_plot[(spotify_sweden_plot['Month'] == 'April')]\n",
    "\n",
    "# Italy data filtered\n",
    "spotify_italy_feb = spotify_italy_plot[(spotify_italy_plot['Month'] == 'February')]\n",
    "spotify_italy_mar = spotify_italy_plot[(spotify_italy_plot['Month'] == 'March')]\n",
    "spotify_italy_apr = spotify_italy_plot[(spotify_italy_plot['Month'] == 'April')]\n",
    "\n",
    "#USA first 6 Months\n",
    "spotify_usa_6mo = spotify_usa_plot.loc[(spotify_usa_plot['Month']=='January') |\n",
    "                              (spotify_usa_plot['Month']=='February') |\n",
    "                              (spotify_usa_plot['Month']=='March') |\n",
    "                              (spotify_usa_plot['Month']=='April') |\n",
    "                              (spotify_usa_plot['Month']=='May') |\n",
    "                              (spotify_usa_plot['Month']=='June')]\n",
    "\n",
    "# USA February Top 50\n",
    "usa_feb_week1 = spotify_usa_feb[spotify_usa_feb['Week']==1].iloc[:50]\n",
    "usa_feb_week2 = spotify_usa_feb[spotify_usa_feb['Week']==2].iloc[:50]\n",
    "usa_feb_week3 = spotify_usa_feb[spotify_usa_feb['Week']==3].iloc[:50]\n",
    "usa_feb_week4 = spotify_usa_feb[spotify_usa_feb['Week']==4].iloc[:50]\n",
    "usa_feb_top50 = usa_feb_week1.append([usa_feb_week2, usa_feb_week3, usa_feb_week4])\n",
    "\n",
    "# Sweden February Top 50\n",
    "sweeden_feb_week1 = spotify_sweden_feb[spotify_sweden_feb['Week']==1].iloc[:50]\n",
    "sweeden_feb_week2 = spotify_sweden_feb[spotify_sweden_feb['Week']==2].iloc[:50]\n",
    "sweeden_feb_week3 = spotify_sweden_feb[spotify_sweden_feb['Week']==3].iloc[:50]\n",
    "sweeden_feb_week4 = spotify_sweden_feb[spotify_sweden_feb['Week']==4].iloc[:50]\n",
    "sweeden_feb_top50 = sweeden_feb_week1.append([sweeden_feb_week2, sweeden_feb_week3, sweeden_feb_week4])\n",
    "\n",
    "# Italy February Top 50\n",
    "italy_feb_week1 = spotify_italy_feb[spotify_italy_feb['Week']==1].iloc[:50]\n",
    "italy_feb_week2 = spotify_italy_feb[spotify_italy_feb['Week']==2].iloc[:50]\n",
    "italy_feb_week3 = spotify_italy_feb[spotify_italy_feb['Week']==3].iloc[:50]\n",
    "italy_feb_week4 = spotify_italy_feb[spotify_italy_feb['Week']==4].iloc[:50]\n",
    "italy_feb_top50 = italy_feb_week1.append([italy_feb_week2, italy_feb_week3, italy_feb_week4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mood in 2020 in Sweden, Italy & USA\n",
    "radar_plot(True, spotify_italy_plot, spotify_sweden_plot, spotify_usa_6mo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Density Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweden, Italy and USA on February\n",
    "density_plot(spotify_sweden, spotify_italy, spotify_usa_6mo, 'February', 'February', 'February', 'Sweden', 'Italy', 'USA', 'Valence', 'Density Plot of Sweden, Italy and USA in February (Valence)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweden, Italy and USA on March\n",
    "density_plot(spotify_sweden, spotify_italy, spotify_usa_6mo, 'March', 'March', 'March', 'Sweden', 'Italy', 'USA', 'Valence', 'Density Plot of Sweden, Italy and USA in March (Valence)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweden, Italy and USA on April\n",
    "density_plot(spotify_sweden, spotify_italy, spotify_usa_6mo, 'April', 'April', 'April', 'Sweden', 'Italy', 'USA', 'Valence', 'Density Plot of Sweden, Italy and USA in April (Valence)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate difference between the Mean Valence in Sweden and Italy\n",
    "sweden_mean = []\n",
    "italy_mean = []\n",
    "sweden_diff = []\n",
    "italy_diff = []\n",
    "group_italy = spotify_italy.groupby('Month', sort=False)\n",
    "group_italy = group_italy.mean()\n",
    "group_sweden = spotify_sweden.groupby('Month', sort=False)\n",
    "group_sweden = group_sweden.mean()\n",
    "\n",
    "for sweden in group_sweden.index:\n",
    "    sweden_mean.append(group_sweden.loc[sweden]['Valence'])\n",
    "for italy in group_italy.index:\n",
    "    italy_mean.append(group_italy.loc[italy]['Valence'])\n",
    "    \n",
    "zip_object = zip(sweden_mean, italy_mean)\n",
    "for sweden_mean, italy_mean in zip_object:\n",
    "        diff = sweden_mean - italy_mean\n",
    "        if diff >= 0:\n",
    "            sweden_diff.append(diff)\n",
    "            italy_diff.append(0)\n",
    "        elif diff < 0:\n",
    "            sweden_diff.append(0)\n",
    "            italy_diff.append(diff)\n",
    "            \n",
    "            \n",
    "# Bar Plot of Italy vs Sweden\n",
    "x = range(len(sweden_diff))\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "plt.bar(x, italy_diff, width=0.5, color='deeppink')\n",
    "plt.bar(x, sweden_diff, width=0.5, color='green')\n",
    "labels = ['Italy', 'Sweden']\n",
    "plt.ylim(-0.02, 0.02)\n",
    "plt.title('Sweden vs Italy Valence')\n",
    "plt.xticks([0, 1, 2, 3, 4, 5], ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun'])\n",
    "plt.xlabel('Months')\n",
    "plt.legend(labels)\n",
    "plt.ylabel('Valence Mean Difference')\n",
    "plt.savefig('output_plots/Bar_Valence_Italy_Sweden.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Weeknd Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_complete = pd.concat([original_spotify20_df, original_spotify21_df])\n",
    "weeknd = spotify_complete.loc[spotify_complete['Artist'] == 'The Weeknd']\n",
    "blinding_lights = pd.DataFrame(weeknd.loc[weeknd['Track Name'] == 'Blinding Lights'])\n",
    "\n",
    "# Create a column: Total Week Count to be used as x-axis\n",
    "week_count = []\n",
    "count = 0\n",
    "for x in range(58):\n",
    "    count += 1\n",
    "    week_count.append(count)\n",
    "blinding_lights['Total Week Count'] = week_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Plot Font Color to White\n",
    "plt.rcParams['text.color'] = 'White'\n",
    "plt.rcParams['axes.labelcolor'] = 'White'\n",
    "plt.rcParams['xtick.color'] = 'White'\n",
    "plt.rcParams['ytick.color'] = 'White'\n",
    "# Create Plots\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(blinding_lights['Total Week Count'], blinding_lights['Position'], color='b')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Total Week Count', fontsize=20)\n",
    "plt.tick_params(axis='x', labelsize=18)\n",
    "plt.ylabel('Position', fontsize=20)\n",
    "plt.tick_params(axis='y', labelsize=18)\n",
    "plt.axvline(12, color='r')\n",
    "plt.axvline(48, color='r')\n",
    "plt.axvline(57, color='r')\n",
    "plt.title('\"Blinding Lights\" Top 200 Chart Position by Week from January 2020 to February 2021', fontsize=30)\n",
    "plt.savefig('output_plots/blinding_lights_position_RM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------#\n",
    "#        \"Blinding Lights\" Stream Count by Week from January 2020 to February 2021         #\n",
    "#------------------------------------------------------------------------------------------#\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(blinding_lights['Total Week Count'], blinding_lights['Streams'], color='b')\n",
    "plt.xlabel('Total Week Count', fontsize=20)\n",
    "plt.tick_params(axis='x', labelsize=18)\n",
    "plt.ylabel('Streams', fontsize=20)\n",
    "plt.tick_params(axis='y', labelsize=18)\n",
    "plt.axvline(12, color='r')\n",
    "plt.axvline(48, color='r')\n",
    "plt.axvline(57, color='r')\n",
    "plt.title('\"Blinding Lights\" Stream Count by Week from January 2020 to February 2021', fontsize=30)\n",
    "plt.savefig('output_plots/blinding_lights_stream_count_RM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------#\n",
    "#       Blinding lights pie chart       #\n",
    "#---------------------------------------#\n",
    "\n",
    "# Create Variables to be used in pie chart\n",
    "bl_sum = blinding_lights['Streams'].sum()\n",
    "else_sum = weeknd['Streams'].sum() - bl_sum\n",
    "\n",
    "# create piechart\n",
    "comparison = [bl_sum, else_sum]\n",
    "labels = [f'Blinding Lights Total Streams ({bl_sum})', f'Other Songs by The Weeknd ({else_sum})']\n",
    "colors= ['lightskyblue', 'blue']\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.pie(comparison, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, textprops={'fontsize': 18})\n",
    "plt.title('Distribution of Total Streams by The Weeknd', fontsize=30)\n",
    "plt.savefig('output_plots/blinding_lights_pie_RM.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
